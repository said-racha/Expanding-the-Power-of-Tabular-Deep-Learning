{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## TABM"
      ],
      "metadata": {
        "id": "32g8j0cZUseo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "# ===== LAYERS =====\n",
        "\n",
        "class linear_BE(nn.Module):\n",
        "    def __init__(self, in_features: int, out_features: int, k=32, dropout_rate=0.1, initialize_to_1=False):\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.k = k\n",
        "\n",
        "        if initialize_to_1:  # For TabM\n",
        "            self.R = nn.Parameter(torch.ones(k, in_features))\n",
        "            self.S = nn.Parameter(torch.ones(k, out_features))\n",
        "        else:\n",
        "            # Paper generates randomly with +-1\n",
        "            self.R = nn.Parameter(torch.zeros((k, in_features)))\n",
        "            nn.init.uniform_(self.R, -1, 1)\n",
        "            self.S = nn.Parameter(torch.zeros((k, out_features)))\n",
        "            nn.init.uniform_(self.S, -1, 1)\n",
        "\n",
        "        self.W = nn.Parameter(torch.zeros((in_features, out_features)))\n",
        "        nn.init.uniform_(self.W, -1, 1)\n",
        "        self.B = nn.Parameter(torch.zeros((k, out_features)))\n",
        "        nn.init.uniform_(self.B, -1, 1)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, X: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Shapes:\n",
        "\n",
        "        X: (batch_size, k, in_features)\n",
        "        R: (k, in_features)\n",
        "        W: (in_features, out_features)\n",
        "        S: (k, out_features)\n",
        "        B: (k, out_features)\n",
        "        output: (batch_size, k, out_features)\n",
        "\n",
        "        Formula:\n",
        "        output = ( (X * R) W) * S + B\n",
        "        \"\"\"\n",
        "        output = X * self.R\n",
        "\n",
        "        output = torch.einsum(\"bki,io->bko\", output, self.W)\n",
        "        output = output * self.S + self.B\n",
        "        output = self.relu(output)\n",
        "        output = self.dropout(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def extra_repr(self):\n",
        "        \"\"\"\n",
        "        Adds information about the layer to its string representation (useful when printing the model)\n",
        "        \"\"\"\n",
        "        return f\"in_features={self.in_features}, out_features={self.out_features}\"\n",
        "\n",
        "\n",
        "class MLP_layer(nn.Module):\n",
        "    def __init__(self, in_features: int, out_features: int, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "\n",
        "        self.linear = nn.Linear(in_features, out_features)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, X: torch.Tensor):\n",
        "        output = self.linear(X)\n",
        "        output = self.relu(output)\n",
        "        output = self.dropout(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def extra_repr(self):\n",
        "        return f\"in_features={self.in_features}, out_features={self.out_features}\"\n",
        "\n",
        "\n",
        "class MLPk_layer(nn.Module):\n",
        "    def __init__(self, in_features: int, out_features: int, k=32, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "\n",
        "        self.W = nn.Parameter(torch.zeros((k, in_features, out_features)))\n",
        "        nn.init.uniform_(self.W, -1, 1)\n",
        "        self.B = nn.Parameter(torch.zeros((k, out_features)))\n",
        "        nn.init.uniform_(self.B, -1, 1)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, X: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Shapes:\n",
        "\n",
        "        X: (batch_size, k, in_features)\n",
        "        W: (k, in_features, out_features)\n",
        "        B: (k, out_features)\n",
        "        output: (batch_size, k, out_features)\n",
        "\n",
        "        Formula:\n",
        "        output = X @ W + B\n",
        "        \"\"\"\n",
        "        output = torch.einsum(\"bki,kio->bko\", X, self.W)\n",
        "        output = output + self.B\n",
        "\n",
        "        output = self.relu(output)\n",
        "        output = self.dropout(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def extra_repr(self):\n",
        "        return f\"in_features={self.in_features}, out_features={self.out_features}\"\n",
        "\n",
        "\n",
        "# ===== BACKBONES =====\n",
        "\n",
        "\n",
        "class TabM_naive(nn.Module):\n",
        "    def __init__(self, in_features: int, hidden_sizes: int, k=32, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_features = in_features\n",
        "        self.hidden_sizes = hidden_sizes\n",
        "        self.k = k\n",
        "\n",
        "        layer_sizes = [in_features] + hidden_sizes\n",
        "\n",
        "        layers = [linear_BE(layer_sizes[i], layer_sizes[i+1], k, dropout_rate) for i in range(len(layer_sizes)-1)]\n",
        "\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, X: torch.Tensor):\n",
        "        return self.layers(X)\n",
        "\n",
        "\n",
        "class TabM_mini(nn.Module):\n",
        "    def __init__(self, in_features: int, hidden_sizes: int, k=32, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.k = k\n",
        "\n",
        "        self.R = nn.Parameter(torch.randn(k, in_features))\n",
        "\n",
        "        layer_sizes = [in_features] + hidden_sizes\n",
        "\n",
        "        layers = [MLP_layer(layer_sizes[i], layer_sizes[i+1], dropout_rate) for i in range(len(layer_sizes)-1)]\n",
        "\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, X: torch.Tensor):\n",
        "        output = X * self.R\n",
        "        return self.layers(output)\n",
        "\n",
        "\n",
        "class TabM(nn.Module):\n",
        "    def __init__(self, in_features: int, hidden_sizes: int, k=32, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.k = k\n",
        "\n",
        "        layer_sizes = [in_features] + hidden_sizes\n",
        "\n",
        "        layers = [linear_BE(layer_sizes[i], layer_sizes[i+1], k, dropout_rate, initialize_to_1=True) for i in range(len(layer_sizes)-1)]\n",
        "\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, X: torch.Tensor):\n",
        "        return self.layers(X)\n",
        "\n",
        "\n",
        "class MLPk(nn.Module):\n",
        "    def __init__(self, in_features: int, hidden_sizes: int, k=32, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        layer_sizes = [in_features] + hidden_sizes\n",
        "\n",
        "        layers = [MLPk_layer(layer_sizes[i], layer_sizes[i+1], k, dropout_rate) for i in range(len(layer_sizes)-1)]\n",
        "\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, X: torch.Tensor):\n",
        "        return self.layers(X)\n",
        "\n",
        "# ===== MODELS =====\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    \"\"\"\n",
        "    Simple MLP model\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_features: int, hidden_sizes: int, out_features: int, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "\n",
        "        layer_sizes = [in_features] + hidden_sizes + [out_features]\n",
        "\n",
        "        layers = [*[MLP_layer(layer_sizes[i], layer_sizes[i+1], dropout_rate) for i in range(len(layer_sizes)-1)],\n",
        "                  nn.Linear(layer_sizes[-1], out_features)\n",
        "                  ]\n",
        "\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, X: torch.Tensor):\n",
        "        return self.layers(X)\n",
        "\n",
        "\n",
        "class EnsembleModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Global ensemble model that :\n",
        "    - takes batched input (batch, in_features)\n",
        "    - clones it k times (batch, k, in_features)\n",
        "    - passes it through a backbone (which model you want e.g TabM, MLPk, etc.) (batch, k, hidden_sizes[-1])\n",
        "    - passes the output through k prediction heads, mean over heads (batch, out_features)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, backbone: nn.Module, in_features: int, hidden_sizes: int, out_features: int, k=32, dropout_rate=0.1, mean_over_heads=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.backbone = backbone(in_features, hidden_sizes, k, dropout_rate)\n",
        "        self.in_features = in_features\n",
        "        self.k = k\n",
        "\n",
        "        self.mean_over_heads = mean_over_heads\n",
        "\n",
        "        self.pred_heads = nn.ModuleList([nn.Linear(hidden_sizes[-1], out_features) for _ in range(k)])\n",
        "\n",
        "    def forward(self, X: torch.Tensor):\n",
        "        # clone X to shape (batch, k, dim)\n",
        "        X = X.unsqueeze(1).repeat(1, self.k, 1)\n",
        "\n",
        "        # pass through backbone\n",
        "        X = self.backbone(X)\n",
        "\n",
        "        # pass through prediction heads\n",
        "        preds = [head(X[:, i]) for i, head in enumerate(self.pred_heads)]\n",
        "\n",
        "        # concatenate head predictions\n",
        "        preds = torch.stack(preds, dim=1)\n",
        "\n",
        "        if self.mean_over_heads:\n",
        "            preds = preds.mean(dim=1)\n",
        "\n",
        "        return preds\n",
        "\n"
      ],
      "metadata": {
        "id": "IX9-7fhJUvzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prunning"
      ],
      "metadata": {
        "id": "yCcK7kxiIca-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class PrunableEnsembleModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Ensemble model avec mécanisme de pruning :\n",
        "    - Mesure la contribution individuelle de chaque sous-modèle.\n",
        "    - Permet de supprimer progressivement les sous-modèles les moins performants.\n",
        "    \"\"\"\n",
        "    def __init__(self, backbone: nn.Module, in_features: int, hidden_sizes: int, out_features: int, k=32, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.backbone = backbone(in_features, hidden_sizes, k, dropout_rate)\n",
        "        self.in_features = in_features\n",
        "        self.hidden_sizes = hidden_sizes\n",
        "        self.k = k\n",
        "        self.out_features = out_features\n",
        "\n",
        "        # Prédiction par sous-modèle (on ne moyenne pas contrairement à ce qu'on fait dans la classe EnsembleModel)\n",
        "        self.pred_heads = nn.ModuleList([nn.Linear(hidden_sizes[-1], out_features) for _ in range(k)])\n",
        "\n",
        "    def forward(self, X: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Forward pass :\n",
        "        - Les prédictions de chaque sous-modèle sont concaténées.\n",
        "        \"\"\"\n",
        "        # Répliquer X pour chaque sous-modèle\n",
        "        X = X.unsqueeze(1).repeat(1, self.k, 1)\n",
        "\n",
        "        # Passer par le backbone\n",
        "        X = self.backbone(X)  # (batch, k, hidden_sizes[-1])\n",
        "\n",
        "        # Prédictions de chaque sous-modèle\n",
        "        preds = [head(X[:, i]) for i, head in enumerate(self.pred_heads)]\n",
        "        preds = torch.stack(preds, dim=1)  # (batch, k, out_features)\n",
        "\n",
        "        return preds\n",
        "\n",
        "    def prune(self, X: torch.Tensor, y: torch.Tensor, keep_ratio=0.5, task_type=\"binary\"):\n",
        "      \"\"\"\n",
        "      Pruning des sous-modèles :\n",
        "      - Garde un ratio donné des sous-modèles avec les meilleures performances.\n",
        "      - Suppression des sous-modèles moins performants.\n",
        "      - S'adapte aux tâches de classification binaire, multiclass ou de régression.\n",
        "\n",
        "      Args:\n",
        "          X : Entrée des données.\n",
        "          y : Labels ou valeurs cibles.\n",
        "          keep_ratio : Ratio de sous-modèles à conserver.\n",
        "          task_type : Type de tâche ('binary', 'multiclass', ou 'regression').\n",
        "      \"\"\"\n",
        "      if not (0 < keep_ratio <= 1):\n",
        "          raise ValueError(\"keep_ratio doit être un float entre 0 et 1.\")\n",
        "\n",
        "      with torch.no_grad():\n",
        "\n",
        "          if task_type == \"binary\":\n",
        "              criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
        "              y = y.float().view(-1, 1)\n",
        "          elif task_type == \"multiclass\":\n",
        "              criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "          elif task_type == \"regression\":\n",
        "              criterion = nn.MSELoss(reduction=\"none\")\n",
        "          else:\n",
        "              raise ValueError(\"task_type must be one of 'binary', 'multiclass', or 'regression'.\")\n",
        "\n",
        "          # Loss\n",
        "          losses = []\n",
        "          preds = self.forward(X)  # (batch, k, out_features)\n",
        "\n",
        "          for i in range(self.k):\n",
        "              if task_type == \"multiclass\":\n",
        "                  loss = criterion(preds[:, i, :], y)\n",
        "              else:\n",
        "                  loss = criterion(preds[:, i, :].reshape(-1, 1), y.reshape(-1, 1))\n",
        "              losses.append(loss.mean().item())  # Moyenne de la perte pour chaque sous-modèle\n",
        "\n",
        "          # Trier les sous-modèles par perte (loss croissante)\n",
        "          sorted_indices = sorted(range(self.k), key=lambda i: losses[i])\n",
        "          keep_count = max(1, int(self.k * keep_ratio))\n",
        "          keep_indices = sorted_indices[:keep_count]\n",
        "\n",
        "          # Mettre à jour les sous-modèles et leurs paramètres\n",
        "          self.pred_heads = nn.ModuleList([self.pred_heads[i] for i in keep_indices])\n",
        "          self.k = keep_count\n",
        "\n",
        "          # Pruning des paramètres du backbone\n",
        "          for layer in self.backbone.layers:\n",
        "              if hasattr(layer, \"R\") and hasattr(layer, \"S\") and hasattr(layer, \"B\"):\n",
        "                  layer.R = nn.Parameter(layer.R[keep_indices])\n",
        "                  layer.S = nn.Parameter(layer.S[keep_indices])\n",
        "                  layer.B = nn.Parameter(layer.B[keep_indices])\n",
        "\n",
        "          # print(f\"Pruning effectué : {len(sorted_indices) - keep_count} sous-modèles supprimés. {self.k} restants.\")\n"
      ],
      "metadata": {
        "id": "27Kz1Ut3vtcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_pruning(model, train_loader, keep_ratios, task_type=\"binary\"):\n",
        "    \"\"\"\n",
        "    Test le mécanisme de pruning.\n",
        "    - Réduit progressivement les sous-modèles.\n",
        "    - Mesure la précision globale après chaque étape.\n",
        "\n",
        "    Args:\n",
        "        model : Modèle prunable.\n",
        "        train_loader : DataLoader pour les données de test.\n",
        "        keep_ratios : Liste des ratios de sous-modèles à conserver.\n",
        "        task_type : Type de tâche ('binary', 'multiclass', ou 'regression').\n",
        "    \"\"\"\n",
        "\n",
        "    for keep_ratio in keep_ratios:\n",
        "        print(f\"\\nPruning avec keep_ratio = {keep_ratio}\")\n",
        "\n",
        "        # Pruning (utiliser un batch pour sélectionner les sous-modèles)\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            model.prune(X_batch, y_batch, keep_ratio, task_type=task_type)\n",
        "            break\n",
        "\n",
        "        # Évaluation des performances après pruning\n",
        "        total_correct = 0\n",
        "        total_samples = 0\n",
        "        total_loss = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in train_loader:\n",
        "                preds = model.forward(X_batch)  # Prédictions des sous-modèles restants\n",
        "\n",
        "                if task_type == \"binary\":\n",
        "                    preds = preds.mean(dim=1)  # Moyenne sur les sous-modèles\n",
        "                    preds_binary = torch.sigmoid(preds)\n",
        "                    preds_binary = (preds_binary > 0.5)\n",
        "                    total_correct += (preds_binary == y_batch.reshape(-1,1)).sum().item()\n",
        "\n",
        "                elif task_type == \"multiclass\":\n",
        "                    preds = preds.mean(dim=1)  # Moyenne sur les sous-modèles\n",
        "                    preds_class = preds.argmax(dim=1)  # Trouver la classe avec la probabilité la plus élevée\n",
        "                    total_correct += (preds_class == y_batch).sum().item()\n",
        "                elif task_type == \"regression\":\n",
        "                    preds = preds.mean(dim=1)  # Moyenne sur les sous-modèles\n",
        "                    total_loss += nn.functional.mse_loss(preds, y_batch).item()\n",
        "\n",
        "                total_samples += y_batch.size(0)\n",
        "\n",
        "        # Calcul des métriques\n",
        "        if task_type in [\"binary\", \"multiclass\"]:\n",
        "            accuracy = total_correct / total_samples\n",
        "            print(f\"Précision globale après pruning : {accuracy:.4f}\")\n",
        "        elif task_type == \"regression\":\n",
        "            avg_loss = total_loss / total_samples\n",
        "            print(f\"Loss moyenne après pruning : {avg_loss:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "figZxvIOvLaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import time\n",
        "\n",
        "# def train_with_pruning(model, train_loader, keep_ratios, task_type=\"binary\", epochs=10, learning_rate=0.001, dataset_name=\"\"):\n",
        "#     \"\"\"\n",
        "#     Entraîne un modèle avec pruning à la fin de chaque epoch.\n",
        "#     - Réduit progressivement les sous-modèles après chaque epoch.\n",
        "#     - Effectue une sélection des modèles basée sur les performances après chaque epoch.\n",
        "\n",
        "#     Args:\n",
        "#         model : Modèle prunable.\n",
        "#         train_loader : DataLoader pour les données d'entraînement.\n",
        "#         keep_ratios : Liste des ratios de sous-modèles à conserver pour chaque epoch.\n",
        "#         task_type : Type de tâche ('binary', 'multiclass', ou 'regression').\n",
        "#         epochs : Nombre d'epochs pour l'entraînement.\n",
        "#         learning_rate : Taux d'apprentissage pour l'optimiseur.\n",
        "#     \"\"\"\n",
        "\n",
        "#     optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "#     # Variables pour le suivi du meilleur modèle\n",
        "#     best_accuracy = 0\n",
        "#     best_model_state = None\n",
        "#     best_keep_ratio = None\n",
        "#     best_epoch = None\n",
        "#     start_time = time.time()  # Début du temps d'entraînement\n",
        "\n",
        "#     for epoch in range(epochs):\n",
        "#         model.train()\n",
        "\n",
        "#         total_correct = 0\n",
        "#         total_samples = 0\n",
        "#         total_loss = 0.0\n",
        "\n",
        "#         with torch.no_grad():\n",
        "#             for X_batch, y_batch in train_loader:\n",
        "#                 preds = model.forward(X_batch)  # Prédictions des sous-modèles restants\n",
        "\n",
        "#                 if task_type == \"binary\":\n",
        "#                     preds = preds.mean(dim=1)  # Moyenne sur les sous-modèles\n",
        "#                     preds_binary = torch.sigmoid(preds)\n",
        "#                     preds_binary = (preds_binary > 0.5)\n",
        "#                     total_correct += (preds_binary == y_batch.reshape(-1, 1)).sum().item()\n",
        "\n",
        "#                 elif task_type == \"multiclass\":\n",
        "#                     preds = preds.mean(dim=1)  # Moyenne sur les sous-modèles\n",
        "#                     preds_class = preds.argmax(dim=1)  # Trouver la classe avec la probabilité la plus élevée\n",
        "#                     total_correct += (preds_class == y_batch).sum().item()\n",
        "#                 elif task_type == \"regression\":\n",
        "#                     preds = preds.mean(dim=1)  # Moyenne sur les sous-modèles\n",
        "#                     total_loss += nn.functional.mse_loss(preds, y_batch).item()\n",
        "\n",
        "#                 total_samples += y_batch.size(0)\n",
        "\n",
        "#         # Calcul de la précision ou de la perte moyenne après chaque epoch\n",
        "#         if task_type in [\"binary\", \"multiclass\"]:\n",
        "#             accuracy = total_correct / total_samples\n",
        "#             # print(f\"Epoch {epoch+1}/{epochs}, Accuracy: {accuracy:.4f}\")\n",
        "#             if accuracy > best_accuracy:\n",
        "#                 best_accuracy = accuracy\n",
        "#                 best_model_state = model.state_dict()\n",
        "#                 # Sauvegarder le keep_ratio correspondant à la meilleure performance\n",
        "#                 best_keep_ratio = keep_ratios[0]  # initialisation avec un keep_ratio\n",
        "#                 best_epoch = epoch + 1\n",
        "#         elif task_type == \"regression\":\n",
        "#             avg_loss = total_loss / total_samples\n",
        "#             # print(f\"Epoch {epoch+1}/{epochs}, Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "#         # Appliquer le pruning après chaque epoch avec un seul keep_ratio\n",
        "#         for keep_ratio in keep_ratios:\n",
        "#             # Appliquer pruning avec ce ratio\n",
        "#             model.prune(X_batch, y_batch, keep_ratio, task_type=task_type)\n",
        "\n",
        "#             # Vérifier la performance après pruning avec ce ratio\n",
        "#             if task_type in [\"binary\", \"multiclass\"]:\n",
        "#                 accuracy = total_correct / total_samples\n",
        "#                 if accuracy > best_accuracy:\n",
        "#                     best_accuracy = accuracy\n",
        "#                     best_keep_ratio = keep_ratio  # Sauvegarder le keep_ratio pour lequel la performance est la meilleure\n",
        "\n",
        "#     total_time = time.time() - start_time\n",
        "\n",
        "#     # Sauvegarder le meilleur modèle\n",
        "#     if best_model_state is not None:\n",
        "#         model.load_state_dict(best_model_state)\n",
        "#         print(f\"\\nOptimal model obtained with keep_ratio = {best_keep_ratio}, achieving an accuracy of {best_accuracy:.4f} in epoch {best_epoch}.\")\n",
        "#         print(f\"Training time: {total_time:.2f} seconds.\")\n",
        "\n",
        "#         torch.save(model.state_dict(), \"best_pruned_model_\" + dataset_name + \".pth\")\n"
      ],
      "metadata": {
        "id": "sD6dXmcHOppx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "QxuZ2VB5Uay5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset \"Breast cancer\""
      ],
      "metadata": {
        "id": "tBgI3oIvUzEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chargement des données\n",
        "data = load_breast_cancer()\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train = torch.tensor(scaler.fit_transform(X_train), dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)  # Reshape pour BCEWithLogitsLoss\n",
        "\n",
        "# DataLoader\n",
        "train_loader = DataLoader(list(zip(X_train, y_train)), batch_size=25, shuffle=True)\n",
        "\n",
        "# Initialisation du modèle\n",
        "layers = [64, 32, 16]\n",
        "prunable_model = PrunableEnsembleModel(TabM, in_features=X_train.shape[1], hidden_sizes=layers, out_features=1, k=32)\n",
        "\n",
        "# Test du pruning\n",
        "keep_ratios = [1, 0.75, 0.5, 0.25, 0.1]  # Réduction progressive\n",
        "test_pruning(prunable_model, train_loader, keep_ratios)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pojSdaO5vR1N",
        "outputId": "74009114-488a-4c0e-f60c-1789125cf30f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Pruning avec keep_ratio = 1\n",
            "Précision globale après pruning : 0.4549\n",
            "\n",
            "Pruning avec keep_ratio = 0.75\n",
            "Précision globale après pruning : 0.6264\n",
            "\n",
            "Pruning avec keep_ratio = 0.5\n",
            "Précision globale après pruning : 0.6396\n",
            "\n",
            "Pruning avec keep_ratio = 0.25\n",
            "Précision globale après pruning : 0.8198\n",
            "\n",
            "Pruning avec keep_ratio = 0.1\n",
            "Précision globale après pruning : 0.6967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "m3ub87fbdrAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "garder le mode des meilleurs ratio à chaque epoch"
      ],
      "metadata": {
        "id": "M8VfAxCsdrwd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "à chaque epoch tester avec un plus faible ratio et un ratio plus elevé"
      ],
      "metadata": {
        "id": "ePFLQ9-ccjtU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Entrainement sur plusieurs epochs\n",
        "# train_with_pruning(prunable_model, train_loader, keep_ratios, epochs=30, learning_rate=0.001, dataset_name=\"cancer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0IVtr0gPD7F",
        "outputId": "0b8d72a0-1ca2-446b-e530-a9e2af0bbd4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Optimal model obtained with keep_ratio = 1, achieving an accuracy of 0.7385 in epoch 28.\n",
            "Training time: 0.85 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset \"Adult income\""
      ],
      "metadata": {
        "id": "yQl7yyrffvQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from tqdm import tqdm\n",
        "\n",
        "def get_adult_income_data(split=0.2, batch_size=32, seed=42):\n",
        "    \"\"\"\n",
        "    Chargement et préparation des données pour la classification `adult income`\n",
        "    \"\"\"\n",
        "    data = pd.read_csv(\"adult.csv\")\n",
        "    X = data.drop(columns='income')\n",
        "    y = data['income']  # target\n",
        "\n",
        "    X = pd.get_dummies(X)\n",
        "\n",
        "    le = LabelEncoder()\n",
        "    y = le.fit_transform(y)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split, random_state=seed)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        torch.utils.data.TensorDataset(torch.tensor(X_train).float(), torch.tensor(y_train).long()),\n",
        "        batch_size=batch_size, shuffle=True\n",
        "    )\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        torch.utils.data.TensorDataset(torch.tensor(X_test).float(), torch.tensor(y_test).long()),\n",
        "        batch_size=batch_size, shuffle=False\n",
        "    )\n",
        "    shape_x = X_train.shape[1]\n",
        "    shape_y = y_train.reshape(-1,1).shape[1]\n",
        "    return train_loader, test_loader, shape_x, shape_y"
      ],
      "metadata": {
        "id": "g771-Wsc0120"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Données\n",
        "BATCH_SIZE = 32\n",
        "train_loader, test_loader, shape_x, shape_y = get_adult_income_data(split=.2, batch_size=BATCH_SIZE, seed=42)\n",
        "\n",
        "# Modèle\n",
        "layers = [64, 32, 16]\n",
        "prunable_model = PrunableEnsembleModel(TabM, in_features=shape_x, hidden_sizes=layers, out_features=1, k=32)\n",
        "\n",
        "# Test du pruning\n",
        "keep_ratios = [1, 0.75, 0.5, 0.25, 0.1]  # Réduction progressive du nombre de sous modèles\n",
        "test_pruning(prunable_model, train_loader, keep_ratios, task_type=\"binary\")\n"
      ],
      "metadata": {
        "id": "OcI2A-HwxELR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba32d15b-a8d8-4026-e653-126faccf4cc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Pruning avec keep_ratio = 1\n",
            "Précision globale après pruning : 0.5129\n",
            "\n",
            "Pruning avec keep_ratio = 0.75\n",
            "Précision globale après pruning : 0.5854\n",
            "\n",
            "Pruning avec keep_ratio = 0.5\n",
            "Précision globale après pruning : 0.7401\n",
            "\n",
            "Pruning avec keep_ratio = 0.25\n",
            "Précision globale après pruning : 0.6917\n",
            "\n",
            "Pruning avec keep_ratio = 0.1\n",
            "Précision globale après pruning : 0.6256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Entrainement sur plusieurs epochs\n",
        "# train_with_pruning(prunable_model, train_loader, keep_ratios, epochs=15, learning_rate=0.001, dataset_name=\"adult\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJ20B1xbSUNA",
        "outputId": "e402f09a-514c-4d5f-e97c-90ba51c2296a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Optimal model obtained with keep_ratio = 1, achieving an accuracy of 0.6302 in epoch 4.\n",
            "Training time: 23.70 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J2DQhkXgSYpQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}